<?xml version="1.0" encoding="utf-8"?><entry xml:lang="en" xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/"><id>http://theorydish.blog/?p=1435</id><link href="https://theorydish.blog/2018/07/20/approximating-edit-distance/" rel="alternate" type="text/html"/><title>Approximating Edit Distance</title><summary>I was excited to see “Approximating Edit Distance Within Constant Factor in Truly Sub-Quadratic Time” by Chakraborty, Das, Goldenberg, Koucky, and Saks in this year’s list of FOCS accepted papers. As you can guess from the title, their main result is a constant-factor approximation for edit distance in truly subquadratic time (i.e. , for some constant ). I spent quite a bit of time thinking about this problem in the past couple of years, and wiser people than me have spent much more time for a couple of decades. Congratulations!! Given strings and of characters each, the textbook dynamic programming algorithm finds their edit distance in time (if you haven’t seen this in your undergrad algorithms class, consider asking your university for a refund on your tuition). Recent complexity breakthroughs [1][2] show that under plausible assumptions like SETH, quadratic time is almost optimal for exact algorithms. This is too bad, because we like to compute edit distance between very long strings, like entire genomes of two organisms (see also this article in Quanta). There is a sequence of near-linear time algorithms with improved approximation factors [1][2][3][4], but until now the state of the art was polylogarithmic; actually for near-linear time, this is [...]<div class="commentbar"><p/></div></summary><content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>I was excited to see “<a href="https://iuuk.mff.cuni.cz/~diptarka/publications/approxEdit.pdf">Approximating Edit Distance Within Constant Factor in Truly Sub-Quadratic Time</a>” by Chakraborty, Das, Goldenberg, Koucky, and Saks in this year’s list of <a href="https://www.irif.fr/~focs2018/accepted">FOCS accepted papers</a>. As you can guess from the title, their main result is a constant-factor approximation for <a href="https://en.wikipedia.org/wiki/Edit_distance">edit distance</a> in truly subquadratic time (i.e. <img alt="O(n^{2-\delta})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B2-%5Cdelta%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(n^{2-\delta})"/>, for some constant <img alt="\delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\delta"/>). I spent quite a bit of time thinking about this problem in the past couple of years, and wiser people than me have spent much more time for a couple of decades. Congratulations!!</p>
<p>Given strings <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A"/> and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/> of <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="n"/> characters each, the textbook dynamic programming algorithm finds their edit distance in time <img alt="O(n^{2})" class="latex" src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B2%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="O(n^{2})"/> (if you haven’t seen this in your undergrad algorithms class, consider asking your university for a refund on your tuition). Recent complexity breakthroughs <a href="https://arxiv.org/abs/1412.0348">[1]</a><a href="https://arxiv.org/abs/1511.06022">[2]</a> show that under plausible assumptions like <a href="https://en.wikipedia.org/wiki/Computational_hardness_assumption#Exponential_Time_Hypothesis_(ETH)_and_variants">SETH</a>, quadratic time is almost optimal for exact algorithms. This is too bad, because we like to compute edit distance between very long strings, like entire genomes of two organisms (see also this <a href="https://www.quantamagazine.org/edit-distance-reveals-hard-computational-problems-20150929/">article</a> in Quanta). There is a sequence of near-linear time algorithms with improved approximation factors <a href="https://www.computer.org/csdl/proceedings/focs/2004/2228/00/22280550-abs.html">[1]</a><a href="https://dl.acm.org/citation.cfm?doid=1284320.1284322">[2]</a><a href="https://arxiv.org/abs/1109.5635">[3]</a><a href="https://arxiv.org/abs/1005.4033">[4]</a>, but until now the state of the art was polylogarithmic; actually for near-linear time, this is still the state of the art:</p>
<p style="padding-left: 30px;"><strong>Open question 1</strong>: Is there a constant-factor approximation to edit distance that runs in near-linear time?</p>
<h2>Algorithm sketch</h2>
<p>Here is a sketch of <em>an </em>algorithm. It is somewhat different from the algorithm in the paper because I wrote this post before finding the full paper online.</p>
<h3>Step 0: window-compatible matchings</h3>
<p>We partition each string into <img alt="t" class="latex" src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t"/> <em>windows</em>, or consecutive substrings of length <img alt="d:=n/t" class="latex" src="https://s0.wp.com/latex.php?latex=d%3A%3Dn%2Ft&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="d:=n/t"/> each. We then restrict our attention to <em>window-compatible</em> matchings: that is, instead of looking for the globally optimum way to transform <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A"/> to <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/>, we look for a partial matching between the <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A"/>– and <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/>-windows, and transform each <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A"/>-window to its matching <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/>-windows (unmatched <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A"/>-windows are deleted, and unmatched <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/>-windows are inserted). It turns out that restricting to window-compatible matchings is almost without loss of generality.</p>
<p>In order to find the optimum window-compatible matching, we can find the distances between every pair of windows, and then use a (weighted) dynamic program of size <img alt="t\times t\ll n^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=t%5Ctimes+t%5Cll+n%5E%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t\times t\ll n^{2}"/>. The reason I call it “Step 0” is because so far we made zero progress on running time: we still have to compute the edit distance between <img alt="t^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=t%5E%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t^{2}"/> pairs, and each computation takes time <img alt="d^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=d%5E%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="d^{2}"/>, so <img alt="t^{2}d^{2}=n^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=t%5E%7B2%7Dd%5E%7B2%7D%3Dn%5E%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t^{2}d^{2}=n^{2}"/> time in total.</p>
<p>Approximating all the pairwise distances reduces to the following problem: given threshold <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Delta"/>, compute the bipartite graph <img alt="G_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}"/> over the windows, where two windows <img alt="A_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{i}"/> and <img alt="B_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=B_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B_{j}"/> share an edge if <img alt="ED (A_i, B_j) \leq \Delta" class="latex" src="https://s0.wp.com/latex.php?latex=ED+%28A_i%2C+B_j%29+%5Cleq+%5CDelta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="ED (A_i, B_j) \leq \Delta"/>. In fact it suffices to compute an approximate <img alt="\widetilde{G}_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BG%7D_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\widetilde{G}_{\Delta}"/>, where <img alt="A_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{i}"/> and <img alt="B_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=B_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B_{j}"/> may share an edge even if their edit distance is a little more than <img alt="\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\Delta"/>.</p>
<p style="padding-left: 30px;"><strong>New Goal</strong>: Compute <img alt="\widetilde{G}_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BG%7D_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\widetilde{G}_{\Delta}"/> faster than naively computing all <img alt="t^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=t%5E%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t^{2}"/> pairwise edit distances.</p>
<h3>Step 1: sparsifying <img alt="G_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}"/></h3>
<p>While there are many edges in <img alt="G_{\Delta}\setminus\widetilde{G}_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D%5Csetminus%5Cwidetilde%7BG%7D_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}\setminus\widetilde{G}_{\Delta}"/>, say average degree <img alt="\geq t^{3/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgeq+t%5E%7B3%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\geq t^{3/4}"/>: Draw a random edge <img alt="(A_{1},B_{1})" class="latex" src="https://s0.wp.com/latex.php?latex=%28A_%7B1%7D%2CB_%7B1%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(A_{1},B_{1})"/>, and let <img alt="B_{j}, A_i" class="latex" src="https://s0.wp.com/latex.php?latex=B_%7Bj%7D%2C+A_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B_{j}, A_i"/> be two other neighbors of <img alt="A_{1},B_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7B1%7D%2CB_%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{1},B_{1}"/>, respectively. Applying the <strong>triangle inequality</strong> (twice), we have that <img alt="ED(A_{i},B_{j})\leq3\Delta" class="latex" src="https://s0.wp.com/latex.php?latex=ED%28A_%7Bi%7D%2CB_%7Bj%7D%29%5Cleq3%5CDelta&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="ED(A_{i},B_{j})\leq3\Delta"/>, so we can immediately add <img alt="(A_{i},B_{j})" class="latex" src="https://s0.wp.com/latex.php?latex=%28A_%7Bi%7D%2CB_%7Bj%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(A_{i},B_{j})"/> to <img alt="\widetilde{G}_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BG%7D_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\widetilde{G}_{\Delta}"/>. In expectation, <img alt="A_{1},B_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7B1%7D%2CB_%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{1},B_{1}"/> have <img alt="\geq t^{3/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgeq+t%5E%7B3%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\geq t^{3/4}"/> neighbors each, so we discovered a total of <img alt="\geq t^{6/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgeq+t%5E%7B6%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\geq t^{6/4}"/> pairs; of which we expect that roughly <img alt="\geq t^{5/4}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cgeq+t%5E%7B5%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\geq t^{5/4}"/> correspond to <em>new</em> edges in <img alt="\widetilde{G}_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BG%7D_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="\widetilde{G}_{\Delta}"/>. Repeat at most <img alt="t^{3/4}" class="latex" src="https://s0.wp.com/latex.php?latex=t%5E%7B3%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t^{3/4}"/> times until we discovered almost all the edges in <img alt="G_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}"/>. Notice that each iteration took us <img alt="td^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=td%5E%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="td^{2}"/> time (computing all the edit distances from <img alt="A_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{1}"/> and <img alt="B_{1}" class="latex" src="https://s0.wp.com/latex.php?latex=B_%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B_{1}"/>); hence in total only <img alt="t^{7/4}d^{2}\ll t^{2}d^{2}=n^{2}" class="latex" src="https://s0.wp.com/latex.php?latex=t%5E%7B7%2F4%7Dd%5E%7B2%7D%5Cll+t%5E%7B2%7Dd%5E%7B2%7D%3Dn%5E%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="t^{7/4}d^{2}\ll t^{2}d^{2}=n^{2}"/>. Thus we reduced to the sparse case in truly subquadratic time.</p>
<p>The algorithm up to this point is actually due to a recent <a href="https://arxiv.org/abs/1804.04178">paper</a> by Boroujeni et al; for the case when <img alt="G_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}"/> is relatively sparse, they use Grover Search to discover all the remaining edges in quantum subquadratic time. It remains to see how to do it classically…</p>
<h3>Step 2: when <img alt="G_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}"/> is relatively sparse</h3>
<p>The main observation we need for this part is that if windows <img alt="A_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{i}"/> and <img alt="A_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{j}"/> are close, then in an optimum window-compatible matching they are probably not matched to <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/>-windows that are very far apart. And in the rare event that they are matched to far-apart <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/>-windows, the cost of inserting so many characters between <img alt="A_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{i}"/> and <img alt="A_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{j}"/> outweighs the cost of completely replacing <img alt="A_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{j}"/> if we had to. So once we have a candidate list of <img alt="B" class="latex" src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="B"/>-windows that <img alt="A_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{i}"/> might match to, it is safe to only search for good matches for <img alt="A_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{j}"/> around each of those candidates. But when the graph <img alt="G_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}"/> is sparse, we have such a short list: the neighbors of <img alt="A_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{i}"/>!</p>
<p>We have to be a bit careful: for example, it is possible that <img alt="A_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{i}"/> is not matched to any of its neighbors in <img alt="G_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}"/>. But if we sample enough <img alt="A_{i}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{i}"/>‘s from some interval around <img alt="A_{j}" class="latex" src="https://s0.wp.com/latex.php?latex=A_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="A_{j}"/>, then either (i) at least one of them is matched to a neighbor in <img alt="G_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}"/>; or (ii) <img alt="G_{\Delta}" class="latex" src="https://s0.wp.com/latex.php?latex=G_%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="G_{\Delta}"/> doesn’t contribute much to reducing the edit distance for this interval, so it’s OK to miss some of those edges.</p>
<h2>Improving the approximation factor</h2>
<p>On the back of my virtual envelope, I think the above ideas give a <img alt="(3+\varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%283%2B%5Cvarepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(3+\varepsilon)"/>-approximation. But as far as genomes go, up to a <img alt="(3+\varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%283%2B%5Cvarepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(3+\varepsilon)"/>-approximation, <a href="http://www.viralnova.com/genetic-relatives/">you’re as closely related to your dog as to a banana</a>. So it would be great to improve the approximation factor:</p>
<p style="padding-left: 30px;"><strong>Open question 2</strong>: Is there a <img alt="(1+\varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2B%5Cvarepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(1+\varepsilon)"/>-approximation algorithm for edit distance in truly subquadratic (or near-linear) time?</p>
<p>Note that only the sparsification step loses more than <img alt="(1+\varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2B%5Cvarepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(1+\varepsilon)"/> in approximation. Also, none of the existing fine-grained hardness results rule out an <img alt="(1+\varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2B%5Cvarepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" title="(1+\varepsilon)"/>-approximation, even in linear time!</p></div></content><updated planet:format="July 20, 2018 10:38 AM">2018-07-20T10:38:36Z</updated><published planet:format="July 20, 2018 10:38 AM">2018-07-20T10:38:36Z</published><category term="Uncategorized"/><author><name>aviad.rubinstein</name></author><source><id>https://theorydish.blog</id><logo>https://theorydish.files.wordpress.com/2017/03/cropped-nightdish1.jpg?w=32</logo><link href="https://theorydish.blog/feed/" rel="self" type="application/atom+xml"/><link href="https://theorydish.blog" rel="alternate" type="text/html"/><link href="https://theorydish.blog/osd.xml" rel="search" type="application/opensearchdescription+xml"/><link href="https://theorydish.blog/?pushpress=hub" rel="hub" type="text/html"/><subtitle>Stanford's CS Theory Research Blog</subtitle><title>Theory Dish</title><updated planet:format="December 17, 2018 05:30 AM">2018-12-17T05:30:25Z</updated><planet:module>toc</planet:module><planet:format>atom10</planet:format><planet:http_last_modified>Mon, 19 Nov 2018 02:17:39 GMT</planet:http_last_modified><planet:bozo>false</planet:bozo><planet:items_per_page>40</planet:items_per_page><planet:css-id>theory-dish-stanford-blog</planet:css-id><planet:face>theorydish.png</planet:face><planet:name>Theory Dish: Stanford blog</planet:name><planet:http_status>200</planet:http_status></source></entry>
