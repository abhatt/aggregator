<?xml version="1.0" encoding="utf-8"?><entry xml:lang="en" xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/"><id>http://tcsplus.wordpress.com/?p=305</id><link href="https://tcsplus.wordpress.com/2018/05/25/tcs-talk-wednesday-may-30th-michael-kearns-upenn/" rel="alternate" type="text/html"/><title>TCS+ talk: Wednesday, May 30th — Michael Kearns, UPenn</title><summary>The next and last TCS+ talk for the Spring will take place this coming Wednesday, May 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). Michael Kearns from UPenn will speak about “Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness” (abstract below). Please make sure you reserve a […]<div class="commentbar"><p/></div></summary><content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The next and last TCS+ talk for the Spring will take place this coming Wednesday, May 30th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Michael Kearns </strong>from UPenn will speak about “<em>Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: The most prevalent notions of fairness in machine learning are statistical definitions: they fix a small collection of pre-defined groups, and then ask for parity of some statistic of the classifier across these groups. Constraints of this form are susceptible to intentional or inadvertent “fairness gerrymandering”, in which a classifier appears to be fair on each individual group, but badly violates the fairness constraint on one or more structured subgroups defined over the protected attributes. We propose instead to demand statistical notions of fairness across exponentially (or infinitely) many subgroups, defined by a structured class of functions over the protected attributes. This interpolates between statistical definitions of fairness and recently proposed individual notions of fairness, but raises several computational challenges. It is no longer clear how to audit a fixed classifier to see if it satisfies such a strong definition of fairness.</p>
<p>We prove that the computational problem of auditing subgroup fairness for both equality of false positive rates and statistical parity is equivalent to the problem of weak agnostic learning, which means it is computationally hard in the worst case, even for simple structured subclasses. But it also raises the possibility of applying empirically successful machine learning methods to the problem.</p>
<p>We then derive two algorithms that provably converge to the best fair classifier, given access to oracles which can solve the agnostic learning problem. The algorithms are based on a formulation of subgroup fairness as a two-player zero-sum game between a Learner and an Auditor. Our first algorithm provably converges in a polynomial number of steps. Our second algorithm enjoys only provably asymptotic convergence, but has the merit of simplicity and faster per-step computation. We implement the simpler algorithm using linear regression as a heuristic oracle, and show that we can effectively both audit and learn fair classifiers on real datasets.</p>
<p>Joint work with Seth Neel, Aaron Roth, and Zhiwei Steven Wu.</p></blockquote></div></content><updated planet:format="May 25, 2018 04:02 AM">2018-05-25T04:02:11Z</updated><published planet:format="May 25, 2018 04:02 AM">2018-05-25T04:02:11Z</published><category term="Announcements"/><author><name>plustcs</name></author><source><id>https://tcsplus.wordpress.com</id><logo>https://s0.wp.com/i/buttonw-com.png</logo><link href="https://tcsplus.wordpress.com/feed/" rel="self" type="application/atom+xml"/><link href="https://tcsplus.wordpress.com" rel="alternate" type="text/html"/><link href="https://tcsplus.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/><link href="https://tcsplus.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/><subtitle>A carbon-free dissemination of ideas across the globe.</subtitle><title>TCS+</title><updated planet:format="December 17, 2018 05:30 AM">2018-12-17T05:30:21Z</updated><planet:module>toc</planet:module><planet:format>atom10</planet:format><planet:http_last_modified>Thu, 06 Dec 2018 23:00:33 GMT</planet:http_last_modified><planet:bozo>false</planet:bozo><planet:items_per_page>40</planet:items_per_page><planet:css-id>tcs-seminar-series</planet:css-id><planet:face>seminarseries.png</planet:face><planet:name>TCS+ seminar series</planet:name><planet:http_status>200</planet:http_status></source></entry>
