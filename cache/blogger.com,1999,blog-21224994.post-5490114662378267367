<?xml version="1.0" encoding="utf-8"?><entry xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/"><id>tag:blogger.com,1999:blog-21224994.post-5490114662378267367</id><link href="https://research.googleblog.com/feeds/5490114662378267367/comments/default" rel="replies" type="application/atom+xml"/><link href="https://research.googleblog.com/2017/11/seamless-google-street-view-panoramas.html#comment-form" rel="replies" type="text/html"/><link href="https://www.blogger.com/feeds/21224994/posts/default/5490114662378267367" rel="edit" type="application/atom+xml"/><link href="https://www.blogger.com/feeds/21224994/posts/default/5490114662378267367" rel="self" type="application/atom+xml"/><link href="https://research.googleblog.com/2017/11/seamless-google-street-view-panoramas.html" rel="alternate" type="text/html"/><title>Seamless Google Street View Panoramas</title><content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><span class="byline-author">Posted by Mike Krainin, Software Engineer and Ce Liu, Research Scientist, Machine Perception</span><br/><br/>In 2007, we introduced <a href="https://www.google.com/streetview/">Google Street View</a>, enabling you to explore the world through panoramas of neighborhoods, landmarks, museums and more, right from your browser or mobile device. The creation of these panoramas is a complicated process, involving capturing images from a multi-camera rig called a rosette, and then using image blending techniques to carefully stitch them all together. However, many things can thwart the creation of a &quot;successful&quot; panorama, such as mis-calibration of the rosette camera geometry, timing differences between adjacent cameras, and <a href="https://en.wikipedia.org/wiki/Parallax">parallax</a>. And while we attempt to address these issues by using approximate scene geometry to account for parallax and frequent camera re-calibration, visible seams in image overlap regions can still occur. <br/><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://4.bp.blogspot.com/-eMyMcE1Lrzw/WgOOljjq8jI/AAAAAAAACLI/GQokAlRZQ4QWeldN5OmdwwtiPPgxnOk5gCLcBGAs/s1600/image18.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="228" src="https://4.bp.blogspot.com/-eMyMcE1Lrzw/WgOOljjq8jI/AAAAAAAACLI/GQokAlRZQ4QWeldN5OmdwwtiPPgxnOk5gCLcBGAs/s640/image18.png" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Left: A Street View car carrying a multi-camera rosette. Center: A close-up of the rosette, which is made up of 15 cameras. Right: A visualization of the spatial coverage of each camera. Overlap between adjacent cameras is shown in darker gray.</td></tr></tbody></table><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://2.bp.blogspot.com/-ylBIpwy26_A/WgOPwpsURNI/AAAAAAAACLU/YocLgJztmxM6ZgCPsWF1mzbKwtlLWtbOACLcBGAs/s1600/f2.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="318" src="https://2.bp.blogspot.com/-ylBIpwy26_A/WgOPwpsURNI/AAAAAAAACLU/YocLgJztmxM6ZgCPsWF1mzbKwtlLWtbOACLcBGAs/s640/f2.png" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Left: The Sydney Opera House with stitching seams along its iconic shells. Right: The same Street View panorama after optical flow seam repair. </td></tr></tbody></table>In order to provide more seamless Street View images, we’ve developed a new algorithm based on <a href="https://en.wikipedia.org/wiki/Optical_flow">optical flow</a> to help solve these challenges. The idea is to subtly warp each input image such that the image content lines up within regions of overlap. This needs to be done carefully to avoid introducing new types of visual artifacts. The approach must also be robust to varying scene geometry, lighting conditions, calibration quality, and many other conditions. To simplify the task of aligning the images and to satisfy computational requirements, we’ve broken it into two steps.<br/><br/><b>Optical Flow</b><br/>The first step is to find corresponding pixel locations for each pair of images that overlap. Using techniques described in our <a href="https://research.googleblog.com/2017/04/photoscan-taking-glare-free-pictures-of.html">PhotoScan blog post</a>, we compute optical flow from one image to the other. This provides a smooth and dense correspondence field. We then downsample the correspondences for computational efficiency. We also discard correspondences where there isn’t enough visual structure to be confident in the results of optical flow.<br/><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-3_PrlnlalVU/WgOQEK4XR3I/AAAAAAAACLY/mMi33cRq2cI9CeEtRefR_Pl_WsZWslm-gCLcBGAs/s1600/image10.jpg" style="margin-left: auto; margin-right: auto;"><img border="0" height="216" src="https://1.bp.blogspot.com/-3_PrlnlalVU/WgOQEK4XR3I/AAAAAAAACLY/mMi33cRq2cI9CeEtRefR_Pl_WsZWslm-gCLcBGAs/s640/image10.jpg" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><br/>The boundaries of a pair of constituent images from the rosette camera rig that need to be stitched together.</td></tr></tbody></table><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://4.bp.blogspot.com/-K0K3_q-6jYU/WgOQP67vylI/AAAAAAAACLg/sk-tnUCPI3wu7URyuASe6Zaqf365nRcggCLcBGAs/s1600/image4.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="493" src="https://4.bp.blogspot.com/-K0K3_q-6jYU/WgOQP67vylI/AAAAAAAACLg/sk-tnUCPI3wu7URyuASe6Zaqf365nRcggCLcBGAs/s640/image4.gif" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">An illustration of optical flow within the pair’s overlap region.</td></tr></tbody></table><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-dGwhq-Fj7x0/WgOQjgj8IPI/AAAAAAAACLk/B5N6K-jOsZ4y5i1U_XHatx5tGfOb3LWhgCLcBGAs/s1600/f5.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="420" src="https://1.bp.blogspot.com/-dGwhq-Fj7x0/WgOQjgj8IPI/AAAAAAAACLk/B5N6K-jOsZ4y5i1U_XHatx5tGfOb3LWhgCLcBGAs/s640/f5.png" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Extracted correspondences in the pair of images. For each colored dot in the overlap region of the left image, there is an equivalently-colored dot in the overlap region of the right image, indicating how the optical flow algorithm has aligned the point. These pairs of corresponding points are used as input to the global optimization stage. Notice that the overlap covers only a small portion of each image.</td></tr></tbody></table><b>Global Optimization</b><br/>The second step is to warp the rosette’s images to simultaneously align all of the corresponding points from overlap regions (as seen in the figure above). When stitched into a panorama, the set of warped images will then properly align. This is challenging because the overlap regions cover only a small fraction of each image, resulting in an under-constrained problem. To generate visually pleasing results across the whole image, we formulate the warping as a <a href="https://en.wikipedia.org/wiki/Spline_(mathematics)">spline</a>-based flow field with spatial regularization. The spline parameters are solved for in a non-linear optimization using Google’s open source <a href="http://ceres-solver.org/">Ceres Solver</a>.<br/><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-Q6T-1Xy7gvM/WgOREyAmTdI/AAAAAAAACLw/a165a0SIOwo1JggsjEsaR550qj6iFklNACLcBGAs/s1600/image6.gif" style="margin-left: auto; margin-right: auto;"><img border="0" height="210" src="https://1.bp.blogspot.com/-Q6T-1Xy7gvM/WgOREyAmTdI/AAAAAAAACLw/a165a0SIOwo1JggsjEsaR550qj6iFklNACLcBGAs/s640/image6.gif" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">A visualization of the final warping process. Left: A section of the panorama covering 180 degrees horizontally. Notice that the overall effect of warping is intentionally quite subtle. Right: A close-up, highlighting how warping repairs the seams.</td></tr></tbody></table>Our approach has many similarities to <a href="https://link.springer.com/chapter/10.1007%2F978-1-4757-3482-9_13">previously published work</a> by Shum &amp; Szeliski on “deghosting” panoramas. Key differences include that our approach estimates dense, smooth correspondences (rather than patch-wise, independent correspondences), and we solve a nonlinear optimization for the final warping. The result is a more well-behaved warping that is less likely to introduce new visual artifacts than the kernel-based approach.<br/><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-sEQuEAh8EbM/WgORZRJ3QSI/AAAAAAAACL0/lhQygBYEP6YUvD75M5NY5u-3I0yJFiwSACLcBGAs/s1600/f7.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="210" src="https://1.bp.blogspot.com/-sEQuEAh8EbM/WgORZRJ3QSI/AAAAAAAACL0/lhQygBYEP6YUvD75M5NY5u-3I0yJFiwSACLcBGAs/s640/f7.png" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Left: A close-up of the un-repaired panorama. Middle: Result of kernel-based interpolation. This fixes discontinuities but at the expense of strong wobbling artifacts due to the small image overlap and limited footprint of kernels. Right: Result of our global optimization.</td></tr></tbody></table>This is important because our algorithm needs to be robust to the enormous diversity in content in Street View’s billions of panoramas. You can see how effective the algorithm is in the following examples:<br/><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://4.bp.blogspot.com/-eB5einc7rZE/WgORrU9lYjI/AAAAAAAACME/FEAQE0EmOw4MTfIsMj0qYwXP0kc3k9-sgCLcBGAs/s1600/f8.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="316" src="https://4.bp.blogspot.com/-eB5einc7rZE/WgORrU9lYjI/AAAAAAAACME/FEAQE0EmOw4MTfIsMj0qYwXP0kc3k9-sgCLcBGAs/s640/f8.png" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Tower Bridge, London</td></tr></tbody></table><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-CPD78I6VFyg/WgORrKvdinI/AAAAAAAACL8/WU-egRbXeHgoThki8D8tyCHzk3G2iJb7wCLcBGAs/s1600/f9.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="318" src="https://1.bp.blogspot.com/-CPD78I6VFyg/WgORrKvdinI/AAAAAAAACL8/WU-egRbXeHgoThki8D8tyCHzk3G2iJb7wCLcBGAs/s640/f9.png" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Christ the Redeemer, Rio de Janeiro</td></tr></tbody></table><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-IQjjDs-C4dc/WgORrKCol_I/AAAAAAAACMA/_KaAY-GOx1o2NKlE-Oo3WW0RAiXZxEoHgCLcBGAs/s1600/f10.png" style="margin-left: auto; margin-right: auto;"><img border="0" height="318" src="https://1.bp.blogspot.com/-IQjjDs-C4dc/WgORrKCol_I/AAAAAAAACMA/_KaAY-GOx1o2NKlE-Oo3WW0RAiXZxEoHgCLcBGAs/s640/f10.png" width="640"/></a></td></tr><tr><td class="tr-caption" style="text-align: center;">An SUV on the streets of Seattle</td></tr></tbody></table>This new algorithm was recently added to the Street View stitching pipeline. It is now being used to restitch existing panoramas on an ongoing basis. Keep an eye out for improved Street View near you!<br/><div class="separator" style="clear: both; text-align: center;"/><br/><b>Acknowledgements</b><br/><i>Special thanks to Bryan Klingner for helping to integrate this feature with the Street View infrastructure.</i></div><div class="commentbar"><p/><span class="commentbutton" href="https://research.googleblog.com/feeds/5490114662378267367/comments/default"/><a href="https://research.googleblog.com/feeds/5490114662378267367/comments/default"><img class="commenticon" src="/images/feed-icon.png"/> Subscribe to comments</a><![CDATA[  | ]]><a href="https://research.googleblog.com/2017/11/seamless-google-street-view-panoramas.html#comment-form"><img class="commenticon" src="/images/post-icon.png"/> Post a comment</a></div></content><updated planet:format="November 09, 2017 06:30 PM">2017-11-09T18:30:00Z</updated><published planet:format="November 09, 2017 06:30 PM">2017-11-09T18:30:00Z</published><category scheme="http://www.blogger.com/atom/ns#" term="Algorithms"/><category scheme="http://www.blogger.com/atom/ns#" term="Computer Vision"/><category scheme="http://www.blogger.com/atom/ns#" term="Google Maps"/><author><name>Google AI Blog</name><email>noreply@blogger.com</email><uri>https://plus.google.com/101673966767287570260</uri></author><source><id>tag:blogger.com,1999:blog-21224994</id><category term="Machine Learning"/><category term="Google Brain"/><category term="Deep Learning"/><category term="Education"/><category term="University Relations"/><category term="TensorFlow"/><category term="Publications"/><category term="open source"/><category term="Computer Vision"/><category term="Research"/><category term="Natural Language Processing"/><category term="conference"/><category term="Neural Networks"/><category term="conferences"/><category term="Natural Language Understanding"/><category term="Research Awards"/><category term="MOOC"/><category term="Computer Science"/><category term="Machine Perception"/><category term="datasets"/><category term="Machine Intelligence"/><category term="YouTube"/><category term="Awards"/><category term="Algorithms"/><category term="Android"/><category term="Computational Photography"/><category term="Health"/><category term="Quantum Computing"/><category term="Speech"/><category term="Visualization"/><category term="ACM"/><category term="CVPR"/><category term="K-12"/><category term="Structured Data"/><category term="Earth Engine"/><category term="Machine Translation"/><category term="Security and Privacy"/><category term="Voice Search"/><category term="ph.d. fellowship"/><category term="Google Accelerated Science"/><category term="HCI"/><category term="Image Processing"/><category term="Search"/><category term="grants"/><category term="AI"/><category term="Collaboration"/><category term="Faculty Summit"/><category term="Graph Mining"/><category term="NIPS"/><category term="TTS"/><category term="Vision Research"/><category term="market algorithms"/><category term="statistics"/><category term="Course Builder"/><category term="Google Cloud Platform"/><category term="Google Genomics"/><category term="Google+"/><category term="Robotics"/><category term="Speech Recognition"/><category term="Translate"/><category term="UI"/><category term="User Experience"/><category term="WWW"/><category term="optimization"/><category term="ACL"/><category term="Fusion Tables"/><category term="Google Books"/><category term="Google Maps"/><category term="ICML"/><category term="Information Retrieval"/><category term="Moore's Law"/><category term="Ngram"/><category term="On-device Learning"/><category term="Physics"/><category term="data science"/><category term="renewable energy"/><category term="App Engine"/><category term="Art"/><category term="Chemistry"/><category term="Computational Imaging"/><category term="Diversity"/><category term="Europe"/><category term="Expander"/><category term="Gmail"/><category term="Google Play Apps"/><category term="Google Translate"/><category term="Hardware"/><category term="ICLR"/><category term="Image Classification"/><category term="Internet of Things"/><category term="Machine Hearing"/><category term="NLP"/><category term="Networks"/><category term="PhD Fellowship"/><category term="Pixel"/><category term="Semi-supervised Learning"/><category term="Software"/><category term="Virtual Reality"/><category term="accessibility"/><category term="crowd-sourcing"/><category term="distributed systems"/><category term="economics"/><category term="internationalization"/><category term="publication"/><category term="search ads"/><category term="wikipedia"/><category term="API"/><category term="Acoustic Modeling"/><category term="App Inventor"/><category term="Audio"/><category term="Automatic Speech Recognition"/><category term="China"/><category term="Cloud Computing"/><category term="Data Discovery"/><category term="DeepDream"/><category term="DeepMind"/><category term="EMEA"/><category term="Environment"/><category term="Exacycle"/><category term="Google Drive"/><category term="Google Science Fair"/><category term="Graph"/><category term="Inbox"/><category term="KDD"/><category term="Labs"/><category term="MapReduce"/><category term="Optical Character Recognition"/><category term="Policy"/><category term="Quantum AI"/><category term="Social Networks"/><category term="Supervised Learning"/><category term="Systems"/><category term="VLDB"/><category term="Video Analysis"/><category term="ads"/><category term="schema.org"/><category term="trends"/><category term="video"/><category term="Adaptive Data Analysis"/><category term="Africa"/><category term="Android Wear"/><category term="April Fools"/><category term="Augmented Reality"/><category term="Australia"/><category term="Cantonese"/><category term="Chrome"/><category term="Conservation"/><category term="Data Center"/><category term="EMNLP"/><category term="Electronic Commerce and Algorithms"/><category term="Encryption"/><category term="Entity Salience"/><category term="Faculty Institute"/><category term="Flu Trends"/><category term="Gboard"/><category term="Google Docs"/><category term="Google Photos"/><category term="Google Sheets"/><category term="Google Trips"/><category term="Google Voice Search"/><category term="Government"/><category term="High Dynamic Range Imaging"/><category term="ICSE"/><category term="IPython"/><category term="Image Annotation"/><category term="India"/><category term="Interspeech"/><category term="Journalism"/><category term="Keyboard Input"/><category term="Klingon"/><category term="Korean"/><category term="Linear Optimization"/><category term="Low-Light Photography"/><category term="ML"/><category term="Magenta"/><category term="Market Research"/><category term="Mixed Reality"/><category term="Multimodal Learning"/><category term="NAACL"/><category term="Network Management"/><category term="Nexus"/><category term="Peer Review"/><category term="PhotoScan"/><category term="PiLab"/><category term="Professional Development"/><category term="Proposals"/><category term="Public Data Explorer"/><category term="SIGCOMM"/><category term="SIGMOD"/><category term="Semantic Models"/><category term="Site Reliability Engineering"/><category term="Style Transfer"/><category term="TPU"/><category term="TV"/><category term="TensorBoard"/><category term="UNIX"/><category term="Visiting Faculty"/><category term="Wiki"/><category term="adsense"/><category term="adwords"/><category term="correlate"/><category term="electronics"/><category term="entities"/><category term="gamification"/><category term="jsm"/><category term="jsm2011"/><category term="localization"/><category term="operating systems"/><category term="osdi"/><category term="osdi10"/><category term="patents"/><category term="resource optimization"/><author><name>Google Blogs</name><email>noreply@blogger.com</email></author><link href="https://research.googleblog.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/><link href="https://www.blogger.com/feeds/21224994/posts/default/-/Algorithms" rel="self" type="application/atom+xml"/><link href="https://research.googleblog.com/search/label/Algorithms" rel="alternate" type="text/html"/><link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/><subtitle>The latest news from Research at Google</subtitle><title>Research Blog</title><updated planet:format="December 15, 2018 12:24 PM">2018-12-15T12:24:56Z</updated><planet:module>toc</planet:module><planet:format>atom10</planet:format><planet:http_etag>W/&quot;d655fa9ddde176e40cae140e16fa1ab52f15af05d220c59bde5ea7ac65f02d30&quot;</planet:http_etag><planet:http_last_modified>Sat, 15 Dec 2018 12:24:56 GMT</planet:http_last_modified><planet:bozo>false</planet:bozo><planet:items_per_page>40</planet:items_per_page><planet:css-id>google-research-blog-algorithms</planet:css-id><planet:face>google.png</planet:face><planet:name>Google Research Blog: Algorithms</planet:name><planet:http_status>200</planet:http_status></source></entry>
