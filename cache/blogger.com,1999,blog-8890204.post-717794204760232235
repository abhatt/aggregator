<?xml version="1.0" ?><entry xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/"><id>tag:blogger.com,1999:blog-8890204.post-717794204760232235</id><link href="http://mybiasedcoin.blogspot.com/feeds/717794204760232235/comments/default" rel="replies" type="application/atom+xml"/><link href="http://www.blogger.com/comment.g?blogID=8890204&amp;postID=717794204760232235" rel="replies" type="text/html"/><link href="http://www.blogger.com/feeds/8890204/posts/default/717794204760232235" rel="edit" type="application/atom+xml"/><link href="http://www.blogger.com/feeds/8890204/posts/default/717794204760232235" rel="self" type="application/atom+xml"/><link href="http://mybiasedcoin.blogspot.com/2018/03/optimizing-learned-bloom-filters.html" rel="alternate" type="text/html"/><title>Optimizing Learned Bloom Filters with Sandwiching</title><content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><br/>For the small-ish subset of people out there who care about &quot;learned Bloom filters&quot; (the subject of my <a href="http://mybiasedcoin.blogspot.com/2018/01/some-notes-on-learned-bloom-filters.html">last post</a>), I have a small-ish update.  I guess the data structure has been unconsciously sitting around in the back of my head, and when I paged it back into my conscious self, I noticed there was an (in hindsight) obvious improvement.  <br/><br/>Recall that the learned Bloom filter uses a (magic) black-box predictor obtained from learning theory that predicts whether an element is in a set or not;  to avoid false negatives, it then uses a backup Bloom filter to rescue any set elements that have been incorrectly predicted as not being in the set.  This leads to two sources of false positives, from the predictor and the backup Bloom filter.<br/><br/>It turns out it is better to get rid of some of those false positives up front.  That is, you get better performance if you have a regular old Bloom filter up front, followed by the learned predictor, followed by a (much smaller) backup Bloom filter to round up stray false negatives.  Because you have the predictor sandwiched between two Bloom filters, I refer to this as the &quot;sandwiched learned Bloom filter&quot;. <br/><br/>The math is surprisingly easily -- and at the same time, really beautiful in terms of the result.  It turns out that, if you think of distributing &quot;Bloom filter bits&quot; out to the up-front Bloom filter and the backup Bloom filter, the right thing to do is first put bits on the backup Bloom filter, up to a certain <b>fixed amount</b>, which depends on the the parameters of the predictor (false positive rate, false negative rate).  After that, all the bits should go to the up-front Bloom filter.<br/><br/>Like most Bloom filter optimizations, the gains are worthwhile but do not seem to be another-factor-of-two;  it looks like it this can cut the size another 10-25% or so, depending on the settings, and it essentially free.    <br/><br/>The whole writeup is less than 2 pages, so rather than write and explain it all here, if you're interested, check the <a href="https://arxiv.org/abs/1803.01474">arxiv draft</a>.  Hopefully, more fun in this setting will be forthcoming....</div></content><updated planet:format="March 06, 2018 08:21 PM">2018-03-06T20:21:00Z</updated><published planet:format="March 06, 2018 08:21 PM">2018-03-06T20:21:00Z</published><author><name>Michael Mitzenmacher</name><email>noreply@blogger.com</email><uri>http://www.blogger.com/profile/02161161032642563814</uri></author><source><id>tag:blogger.com,1999:blog-8890204</id><category term="conferences"/><category term="research"/><category term="society"/><category term="algorithms"/><category term="administration"/><category term="teaching"/><category term="Harvard"/><category term="papers"/><category term="graduate students"/><category term="funding"/><category term="talks"/><category term="blogs"/><category term="codes"/><category term="jobs"/><category term="reviews"/><category term="personal"/><category term="travel"/><category term="undergraduate students"/><category term="books"/><category term="open problems"/><category term="PCs"/><category term="consulting"/><category term="randomness"/><category term="CCC"/><category term="blog book project"/><category term="research labs"/><category term="ISIT"/><category term="tenure"/><category term="comments"/><category term="recommendations"/><category term="outreach"/><category term="students"/><author><name>Michael Mitzenmacher</name><email>noreply@blogger.com</email><uri>http://www.blogger.com/profile/06738274256402616703</uri></author><link href="http://mybiasedcoin.blogspot.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/><link href="http://www.blogger.com/feeds/8890204/posts/default" rel="self" type="application/atom+xml"/><link href="http://mybiasedcoin.blogspot.com/" rel="alternate" type="text/html"/><link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/><link href="http://www.blogger.com/feeds/8890204/posts/default?start-index=26&amp;max-results=25" rel="next" type="application/atom+xml"/><subtitle type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml">My take on computer science -- <br/> 
algorithms, networking, information theory -- <br/> 
and related items.</div></subtitle><title>My Biased Coin</title><updated planet:format="February 27, 2020 09:21 PM">2020-02-27T21:21:48Z</updated><planet:module>toc</planet:module><planet:format>atom10</planet:format><planet:http_etag>W/&quot;477629b01d6b283a23a93d7274d0d13b2105000200f694fda20008900032a203&quot;</planet:http_etag><planet:http_last_modified>Thu, 27 Feb 2020 21:21:48 GMT</planet:http_last_modified><planet:bozo>false</planet:bozo><planet:items_per_page>40</planet:items_per_page><planet:css-id>michael-mitzenmacher</planet:css-id><planet:face>mitzenmacher.jpeg</planet:face><planet:name>Michael Mitzenmacher</planet:name><planet:http_status>200</planet:http_status></source></entry>