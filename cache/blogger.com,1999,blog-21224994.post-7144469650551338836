<?xml version="1.0" encoding="utf-8"?><entry xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/"><id>tag:blogger.com,1999:blog-21224994.post-7144469650551338836</id><link href="https://research.googleblog.com/feeds/7144469650551338836/comments/default" rel="replies" type="application/atom+xml"/><link href="https://research.googleblog.com/2018/03/balanced-partitioning-and-hierarchical.html#comment-form" rel="replies" type="text/html"/><link href="https://www.blogger.com/feeds/21224994/posts/default/7144469650551338836" rel="edit" type="application/atom+xml"/><link href="https://www.blogger.com/feeds/21224994/posts/default/7144469650551338836" rel="self" type="application/atom+xml"/><link href="https://research.googleblog.com/2018/03/balanced-partitioning-and-hierarchical.html" rel="alternate" type="text/html"/><title>Balanced Partitioning and Hierarchical Clustering at Scale</title><content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><span class="byline-author">Posted by Hossein Bateni, Research Scientist and Kevin Aydin, Software Engineer, NYC Algorithms and Optimization Research Team</span><br/><br/>Solving large-scale optimization problems often starts with <a href="https://en.wikipedia.org/wiki/Graph_partition">graph partitioning</a>, which means partitioning the vertices of the graph into clusters to be processed on different machines. The need to make sure that clusters are of near equal size gives rise to the <i>balanced graph partitioning problem</i>. In simple terms, we need to partition the vertices of a given graph into k almost equal clusters, while we minimize the number of edges that are cut by the partition. This <a href="https://en.wikipedia.org/wiki/NP-hardness">NP-hard</a> problem is notoriously difficult in practice because the <a href="http://snap.stanford.edu/class/cs224w-readings/arora04expansion.pdf">best approximation algorithms</a> for small instances rely on <a href="https://en.wikipedia.org/wiki/Semidefinite_programming">semidefinite programming</a> which is impractical for larger instances. <br/><br/>This post presents the distributed algorithm <a href="https://research.google.com/teams/nycalg/graph-mining/">we developed</a> which is more applicable to large instances. We introduced this balanced graph-partitioning algorithm in our <a href="https://dl.acm.org/authorize.cfm?key=N08074">WSDM 2016 paper</a>, and have applied this approach to several applications within Google. Our more recent <a href="https://nips.cc/Conferences/2017/Schedule?showEvent=9453">NIPS 2017 paper</a> provides more details of the algorithm via a theoretical and empirical study.<br/><br/><b>Balanced Partitioning via Linear Embedding</b><br/>Our algorithm first embeds vertices of the graph onto a line, and then processes vertices in a distributed manner guided by the linear embedding order. We examine various ways to find the initial embedding, and apply four different techniques (such as local swaps and dynamic programming) to obtain the final partition. The best initial embedding is based on “<a href="https://papers.nips.cc/paper/7262-affinity-clustering-hierarchical-clustering-at-scale">affinity clustering</a>”.<br/><br/><b>Affinity Hierarchical Clustering</b><br/>Affinity clustering is an agglomerative hierarchical graph clustering based on <a href="https://en.wikipedia.org/wiki/Bor%C5%AFvka%27s_algorithm">Borůvka’s classic Maximum-cost Spanning Tree algorithm</a>. As discussed above, this algorithm is a critical part of our balanced partitioning tool. The algorithm starts by placing each vertex in a cluster of its own: v0, v1, and so on. Then, in each iteration, the highest-cost edge out of each cluster is selected in order to induce larger merged clusters: A<sub>0</sub>, A<sub>1</sub>, A<sub>2</sub>, etc. in the first round and B<sub>0</sub>, B<sub>1</sub>, etc. in the second round and so on. The set of merges naturally produces a hierarchical clustering, and gives rise to a linear ordering of the leaf vertices (vertices with degree one). The image below demonstrates this, with the numbers at the bottom corresponding to the ordering of the vertices.<br/><div class="separator" style="clear: both; text-align: center;"><a href="https://3.bp.blogspot.com/-NgoiCV3R5b8/WqhG7fzZZ3I/AAAAAAAACfU/yPbXncxLylAMIPv5BcpazkiLYyPiC6PgQCLcBGAs/s1600/image1.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="262" src="https://3.bp.blogspot.com/-NgoiCV3R5b8/WqhG7fzZZ3I/AAAAAAAACfU/yPbXncxLylAMIPv5BcpazkiLYyPiC6PgQCLcBGAs/s640/image1.png" width="640"/></a></div>Our <a href="https://papers.nips.cc/paper/7262-affinity-clustering-hierarchical-clustering-at-scale">NIPS’17 paper</a> explains how we run affinity clustering efficiently in the massively parallel computation (MPC) model, in particular using distributed hash tables (<a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHTs</a>) to significantly reduce running time. This paper also presents a theoretical study of the algorithm. We report clustering results for graphs with tens of trillions of edges, and also observe that affinity clustering empirically beats other clustering algorithms such as k-means in terms of “quality of the clusters”. <a href="https://www.youtube.com/watch?v=1IOEFNGPNJc">This video</a> contains a summary of the result and explains how this parallel algorithm may produce higher-quality clusters even compared to a sequential single-linkage agglomerative algorithm.<br/><br/><b>Comparison to Previous Work</b><br/>In comparing our algorithm to previous work in (distributed) balanced graph partitioning, we focus on <a href="https://dl.acm.org/citation.cfm?id=2556213">FENNEL</a>, <a href="http://ieeexplore.ieee.org/document/7930049/">Spinner</a>, <a href="http://glaros.dtc.umn.edu/gkhome/metis/metis/overview">METIS</a>, and a recent <a href="https://dl.acm.org/citation.cfm?id=2433461">label propagation-based algorithm</a>.  We report results on several public social networks as well as a large private map graph.  For a <a href="https://dl.acm.org/citation.cfm?id=1772751">Twitter followership graph</a>, we see a consistent improvement of 15–25% over previous results (<a href="https://dl.acm.org/citation.cfm?id=2433461">Ugander and Backstrom, 2013</a>), and for LiveJournal graph, our algorithm outperforms all the others for all cases except k = 2, where ours is slightly worse than FENNEL's.<br/><br/>The following table presents the fraction of cut edges in the Twitter graph obtained via different algorithms for various values of k, the number of clusters.  The numbers given in parentheses denote the size imbalance factor: i.e., the relative difference of the sizes of largest and smallest clusters.  Here “Vanilla Affinity Clustering” denotes the first stage of our algorithm where only the hierarchical clustering is built and no further processing is performed on the cuts.  Notice that this is already as good as the best previous work (shown in the first two columns below), cutting a smaller fraction of edges while achieving a perfect (and thus better) balance (i.e., 0% imbalance).  The last column in the table includes the final result of our algorithm with the post-processing.<br/><br/><table border="1" cellpadding="1" cellspacing="0" style="width: 100%;"><tbody><tr> <td><div style="text-align: center;"><b>k</b></div></td> <td><div style="text-align: center;"><b><a href="https://dl.acm.org/citation.cfm?id=2433461">UB13</a><br/>(5%)</b></div></td> <td><div style="text-align: center;"><b><a href="http://ieeexplore.ieee.org/document/7930049/">Spinner</a><br/>(5%)</b></div></td>  <td><div style="text-align: center;"><b>Vanilla Affinity<br/>Clustering<br/>(0%)</b></div></td><td><div style="text-align: center;"><b>Final Algorithm<br/>(0%)</b></div></td></tr><tr> <td><div style="text-align: center;"><b>20</b></div></td> <td><div style="text-align: center;">37.0%</div></td> <td><div style="text-align: center;">38.0%</div></td>  <td><div style="text-align: center;">35.71%</div></td><td><div style="text-align: center;">27.50%</div></td></tr><tr> <td><div style="text-align: center;"><b>40</b></div></td> <td><div style="text-align: center;">43.0%</div></td> <td><div style="text-align: center;">40.0%</div></td>  <td><div style="text-align: center;">40.83%</div></td><td><div style="text-align: center;">33.71%</div></td></tr><tr> <td><div style="text-align: center;"><b>60</b></div></td> <td><div style="text-align: center;">46.0%</div></td> <td><div style="text-align: center;">43.0%</div></td>  <td><div style="text-align: center;">43.03%</div></td><td><div style="text-align: center;">36.65%</div></td></tr><tr> <td><div style="text-align: center;"><b>80</b></div></td> <td><div style="text-align: center;">47.5%</div></td> <td><div style="text-align: center;">44.0%</div></td>  <td><div style="text-align: center;">43.27%</div></td><td><div style="text-align: center;">38.65%</div></td></tr><tr> <td><div style="text-align: center;"><b>100</b></div></td> <td><div style="text-align: center;">49.0%</div></td> <td><div style="text-align: center;">46.0%</div></td>  <td><div style="text-align: center;">45.05%</div></td><td><div style="text-align: center;">41.53%</div></td></tr></tbody></table><br/><b>Applications</b><br/>We apply balanced graph partitioning to multiple applications including <a href="https://maps.google.com/">Google Maps</a> driving directions, the serving backend for web search, and finding <a href="https://arxiv.org/abs/1611.03780">treatment groups for experimental design</a>. For example, in Google Maps the World map graph is stored in several <a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)">shards</a>. The navigational queries spanning multiple shards are substantially more expensive than those handled within a shard.  Using the methods described in our paper, we can reduce 21% of cross-shard queries by increasing the shard imbalance factor from 0% to 10%.  As discussed in our paper, live experiments on real traffic show that the number of multi-shard queries from our cut-optimization techniques is 40% less compared to a baseline <a href="https://en.wikipedia.org/wiki/Hilbert_curve#Applications_and_mapping_algorithms">Hilbert embedding</a> technique. This, in turn, results in less CPU usage in response to queries. In a future blog post, we will talk about application of this work in the web search serving backend, where balanced partitioning helped us design a cache-aware load balancing system that dramatically reduced our cache miss rate.<br/><br/><b>Acknowledgements</b><br/><i>We especially thank Vahab Mirrokni whose guidance and technical contribution were instrumental in developing these algorithms and writing this post. We also thank our other co-authors and colleagues for their contributions: Raimondas Kiveris, Soheil Behnezhad, Mahsa Derakhshan, MohammadTaghi Hajiaghayi, Silvio Lattanzi, Aaron Archer and other members of <a href="https://research.google.com/teams/nycalg/">NYC Algorithms and Optimization research team</a>.</i></div><div class="commentbar"><p/><span class="commentbutton" href="https://research.googleblog.com/feeds/7144469650551338836/comments/default"/><a href="https://research.googleblog.com/feeds/7144469650551338836/comments/default"><img class="commenticon" src="/images/feed-icon.png"/> Subscribe to comments</a><![CDATA[  | ]]><a href="https://research.googleblog.com/2018/03/balanced-partitioning-and-hierarchical.html#comment-form"><img class="commenticon" src="/images/post-icon.png"/> Post a comment</a></div></content><updated planet:format="March 14, 2018 05:00 PM">2018-03-14T17:00:00Z</updated><published planet:format="March 14, 2018 05:00 PM">2018-03-14T17:00:00Z</published><category scheme="http://www.blogger.com/atom/ns#" term="Algorithms"/><category scheme="http://www.blogger.com/atom/ns#" term="distributed systems"/><category scheme="http://www.blogger.com/atom/ns#" term="Google Maps"/><category scheme="http://www.blogger.com/atom/ns#" term="Graph Mining"/><author><name>Google AI Blog</name><email>noreply@blogger.com</email><uri>https://plus.google.com/101673966767287570260</uri></author><source><id>tag:blogger.com,1999:blog-21224994</id><category term="Machine Learning"/><category term="Google Brain"/><category term="Deep Learning"/><category term="Education"/><category term="University Relations"/><category term="TensorFlow"/><category term="Publications"/><category term="open source"/><category term="Computer Vision"/><category term="Research"/><category term="Natural Language Processing"/><category term="conference"/><category term="Neural Networks"/><category term="conferences"/><category term="Natural Language Understanding"/><category term="Research Awards"/><category term="MOOC"/><category term="Computer Science"/><category term="Machine Perception"/><category term="datasets"/><category term="Machine Intelligence"/><category term="YouTube"/><category term="Awards"/><category term="Algorithms"/><category term="Android"/><category term="Computational Photography"/><category term="Health"/><category term="Quantum Computing"/><category term="Speech"/><category term="Visualization"/><category term="ACM"/><category term="CVPR"/><category term="K-12"/><category term="Structured Data"/><category term="Earth Engine"/><category term="Machine Translation"/><category term="Security and Privacy"/><category term="Voice Search"/><category term="ph.d. fellowship"/><category term="Google Accelerated Science"/><category term="HCI"/><category term="Image Processing"/><category term="Search"/><category term="grants"/><category term="AI"/><category term="Collaboration"/><category term="Faculty Summit"/><category term="Graph Mining"/><category term="NIPS"/><category term="TTS"/><category term="Vision Research"/><category term="market algorithms"/><category term="statistics"/><category term="Course Builder"/><category term="Google Cloud Platform"/><category term="Google Genomics"/><category term="Google+"/><category term="Robotics"/><category term="Speech Recognition"/><category term="Translate"/><category term="UI"/><category term="User Experience"/><category term="WWW"/><category term="optimization"/><category term="ACL"/><category term="Fusion Tables"/><category term="Google Books"/><category term="Google Maps"/><category term="ICML"/><category term="Information Retrieval"/><category term="Moore's Law"/><category term="Ngram"/><category term="On-device Learning"/><category term="Physics"/><category term="data science"/><category term="renewable energy"/><category term="App Engine"/><category term="Art"/><category term="Chemistry"/><category term="Computational Imaging"/><category term="Diversity"/><category term="Europe"/><category term="Expander"/><category term="Gmail"/><category term="Google Play Apps"/><category term="Google Translate"/><category term="Hardware"/><category term="ICLR"/><category term="Image Classification"/><category term="Internet of Things"/><category term="Machine Hearing"/><category term="NLP"/><category term="Networks"/><category term="PhD Fellowship"/><category term="Pixel"/><category term="Semi-supervised Learning"/><category term="Software"/><category term="Virtual Reality"/><category term="accessibility"/><category term="crowd-sourcing"/><category term="distributed systems"/><category term="economics"/><category term="internationalization"/><category term="publication"/><category term="search ads"/><category term="wikipedia"/><category term="API"/><category term="Acoustic Modeling"/><category term="App Inventor"/><category term="Audio"/><category term="Automatic Speech Recognition"/><category term="China"/><category term="Cloud Computing"/><category term="Data Discovery"/><category term="DeepDream"/><category term="DeepMind"/><category term="EMEA"/><category term="Environment"/><category term="Exacycle"/><category term="Google Drive"/><category term="Google Science Fair"/><category term="Graph"/><category term="Inbox"/><category term="KDD"/><category term="Labs"/><category term="MapReduce"/><category term="Optical Character Recognition"/><category term="Policy"/><category term="Quantum AI"/><category term="Social Networks"/><category term="Supervised Learning"/><category term="Systems"/><category term="VLDB"/><category term="Video Analysis"/><category term="ads"/><category term="schema.org"/><category term="trends"/><category term="video"/><category term="Adaptive Data Analysis"/><category term="Africa"/><category term="Android Wear"/><category term="April Fools"/><category term="Augmented Reality"/><category term="Australia"/><category term="Cantonese"/><category term="Chrome"/><category term="Conservation"/><category term="Data Center"/><category term="EMNLP"/><category term="Electronic Commerce and Algorithms"/><category term="Encryption"/><category term="Entity Salience"/><category term="Faculty Institute"/><category term="Flu Trends"/><category term="Gboard"/><category term="Google Docs"/><category term="Google Photos"/><category term="Google Sheets"/><category term="Google Trips"/><category term="Google Voice Search"/><category term="Government"/><category term="High Dynamic Range Imaging"/><category term="ICSE"/><category term="IPython"/><category term="Image Annotation"/><category term="India"/><category term="Interspeech"/><category term="Journalism"/><category term="Keyboard Input"/><category term="Klingon"/><category term="Korean"/><category term="Linear Optimization"/><category term="Low-Light Photography"/><category term="ML"/><category term="Magenta"/><category term="Market Research"/><category term="Mixed Reality"/><category term="Multimodal Learning"/><category term="NAACL"/><category term="Network Management"/><category term="Nexus"/><category term="Peer Review"/><category term="PhotoScan"/><category term="PiLab"/><category term="Professional Development"/><category term="Proposals"/><category term="Public Data Explorer"/><category term="SIGCOMM"/><category term="SIGMOD"/><category term="Semantic Models"/><category term="Site Reliability Engineering"/><category term="Style Transfer"/><category term="TPU"/><category term="TV"/><category term="TensorBoard"/><category term="UNIX"/><category term="Visiting Faculty"/><category term="Wiki"/><category term="adsense"/><category term="adwords"/><category term="correlate"/><category term="electronics"/><category term="entities"/><category term="gamification"/><category term="jsm"/><category term="jsm2011"/><category term="localization"/><category term="operating systems"/><category term="osdi"/><category term="osdi10"/><category term="patents"/><category term="resource optimization"/><author><name>Google Blogs</name><email>noreply@blogger.com</email></author><link href="https://research.googleblog.com/feeds/posts/default" rel="http://schemas.google.com/g/2005#feed" type="application/atom+xml"/><link href="https://www.blogger.com/feeds/21224994/posts/default/-/Algorithms" rel="self" type="application/atom+xml"/><link href="https://research.googleblog.com/search/label/Algorithms" rel="alternate" type="text/html"/><link href="http://pubsubhubbub.appspot.com/" rel="hub" type="text/html"/><subtitle>The latest news from Research at Google</subtitle><title>Research Blog</title><updated planet:format="December 15, 2018 12:24 PM">2018-12-15T12:24:56Z</updated><planet:module>toc</planet:module><planet:format>atom10</planet:format><planet:http_etag>W/&quot;d655fa9ddde176e40cae140e16fa1ab52f15af05d220c59bde5ea7ac65f02d30&quot;</planet:http_etag><planet:http_last_modified>Sat, 15 Dec 2018 12:24:56 GMT</planet:http_last_modified><planet:bozo>false</planet:bozo><planet:items_per_page>40</planet:items_per_page><planet:css-id>google-research-blog-algorithms</planet:css-id><planet:face>google.png</planet:face><planet:name>Google Research Blog: Algorithms</planet:name><planet:http_status>200</planet:http_status></source></entry>
