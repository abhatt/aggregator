<?xml version="1.0" encoding="utf-8"?><entry xml:lang="en-US" xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/"><id>https://blogs.princeton.edu/imabandit/?p=1302</id><link href="https://blogs.princeton.edu/imabandit/2017/12/16/k-server-part-1-online-learning-and-online-algorithms/" rel="alternate" type="text/html"/><title>k-server, part 1: online learning and online algorithms</title><summary type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p>The -server problem is a classical and very attractive instance of online decision making. The decisions to be made in this problem are simple: given a requested location in some finite metric space and a fleet of k servers currently sitting … <a href="https://blogs.princeton.edu/imabandit/2017/12/16/k-server-part-1-online-learning-and-online-algorithms/">Continue reading <span class="meta-nav">→</span></a></p></div><div class="commentbar"><p/></div></summary><content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><p><a class="liimagelink" href="https://en.wikipedia.org/wiki/K-server_problem" rel="nofollow">The <img alt="k" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9dc53f8ecc1bcf15020c6df4c12f1c27_l3.png?resize=9%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>-server problem</a> is a classical and very attractive instance of online decision making. The decisions to be made in this problem are simple: given a requested location in some finite metric space and a fleet of k servers currently sitting in this metric space, one has to choose which server to use to service the request (that is the server will move from its current location to the requested location). The problem is to minimize the total amount of movement of the servers on a stream of such requests. This formulation is both abstract enough that it can model many real-life problems (e.g., virtual memory management) yet concrete/simple enough that it <em>seems</em> that everything ought to be understood about it.</p>
<p>In the coming series of 5 blog posts I will explain the main ideas behind our <img alt="k" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9dc53f8ecc1bcf15020c6df4c12f1c27_l3.png?resize=9%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>-server preprint with <a class="liinternal" href="https://scholar.google.com/citations?user=t3kDJHQAAAAJ&amp;hl=en">Michael Cohen</a>, <a class="liinternal" href="https://homes.cs.washington.edu/~jrl/">James Lee</a>, <a class="liexternal" href="http://yintat.com/">Yin Tat Lee</a>, and <a class="liexternal" href="http://people.csail.mit.edu/madry/">Aleksander Madry</a>. In this first post I will briefly put the problem in the broader context of <a class="liinternal" href="https://en.wikipedia.org/wiki/Online_machine_learning" rel="nofollow">online learning</a> and <a class="liinternal" href="https://en.wikipedia.org/wiki/Online_algorithm" rel="nofollow">online algorithms</a>, which will be helpful as it suggests an approach based on the <a class="liinternal" href="https://blogs.princeton.edu/imabandit/2013/04/16/orf523-mirror-descent-part-iii/">mirror descent algorithm</a>. In the next post I will explain the general framework of mirror descent and how it can be applied to a problem such as k-server. The third post will show how to use this general framework to recover effortlessly the state of the art for weighted <a class="liinternal" href="https://en.wikipedia.org/wiki/Paging" rel="nofollow">k-paging</a> (i.e., when the underlying metric space is a weighted star). The fourth post will show how to extend the analysis to arbitrary trees. Finally in the fifth post we will discuss both <a class="liinternal" href="https://tcsmath.org/2010/06/19/random-partitions-of-metric-spaces/">classical embedding techniques</a> to reduce the problem to the tree case, as well as our new dynamic embedding based on multiscale restarts on the classical technique. The content of the first three posts was essentially covered in <a class="liinternal" href="https://www.youtube.com/watch?v=UAfo90a4Cg0&amp;t=2056s">my TCS+ seminar talk</a>.</p>
<p><strong>Online decision making: two probability free models</strong></p>
<p>I will start by introducing a very general framework for online algorithms due to Borodin, Linial and Saks 92, called <a class="liinternal" href="https://en.wikipedia.org/wiki/Metrical_task_system" rel="nofollow"><em>metrical task systems</em></a> (MTS). At the same time I will recall the online learning framework, so that one can see the similarities/differences between the two settings. In fact this connection was already made at the end of the Nineties, see <a class="lipdf" href="http://www.win.tue.nl/~nikhil/AU16/reading/blum-burch-learning.pdf">Blum and Burch 00</a>. At the time it was natural to explore the power of multiplicative weights. With today’s perspective it is natural to explore the much more general <em>mirror descent</em> algorithm (we note that the closely related concept of regularization was already brought to bear for these problems in <a class="lipdf" href="http://web.eecs.umich.edu/~jabernet/alt-mts.pdf">Abernethy, Bartlett, Buchbinder and Stanton 10</a>, and <a class="liexternal" href="http://epubs.siam.org/doi/pdf/10.1137/1.9781611973402.32">Buchbinder, Chen and Naor 14</a>).</p>
<p>Let <img alt="X" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2453362c766504f3c3806fed710a5337_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/> be a set which we think of as either a state space (for online algorithms) or an action space (for online learning). Let <img alt="d" class="ql-img-inline-formula " height="13" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ef6965453c87cda7872c06b350e81478_l3.png?resize=10%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> be a metric on <img alt="X" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2453362c766504f3c3806fed710a5337_l3.png?resize=16%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="16"/>. Finally let <img alt="\mathcal{C} \subset \mathbb{R}^{X}" class="ql-img-inline-formula " height="16" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cbe4f0b0f5a53d3e96c3f88bb901d9eb_l3.png?resize=59%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="59"/> be a set of possible cost functions (e.g., arbitrary bounded functions, or linear functions if <img alt="X \subset \mathbb{R}^N" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ed1cedcf529f324e0678612cd0801e3b_l3.png?resize=65%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="65"/>, or convex functions, etc). Online decision making is about making decisions in an uncertain environment (<em>the future is not known</em>), and here we model this uncertain environment as an unknown sequence of cost functions <img alt="c_1, \hdots, c_T \in \mathcal{C}" class="ql-img-inline-formula " height="16" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-07d09bc69304728a5f4d7d20ff1b2bd3_l3.png?resize=105%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="105"/>. The interaction protocol can then be described as follows: For each <img alt="t \in [T]" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-7b76dad5c52f9b6270c6518a4bc657ea_l3.png?resize=49%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="49"/>, the player chooses (possibly randomly) <img alt="x_t \in X" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-7e7ee722fa27f61224c394166e316c61_l3.png?resize=54%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="54"/> based on past observations (to be made precise soon) and pays the cost <img alt="c_t(x_t) \in \mathbb{R}" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2eb130668330e78383f1fd5719ffb5b5_l3.png?resize=78%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="78"/>, plus possibly a movement penalty: <img alt="d(x_{t-1}, x_t)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8e179921204d72c7920449ccf8d5f39c_l3.png?resize=79%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="79"/>.</p>
<p>There are now two key differences between online algorithms and online learning: (i) the observation model, and (ii) the performance metric. In online learning one assumes that the cost <img alt="c_t" class="ql-img-inline-formula " height="11" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9845b6b2f038ab88eb360832403e4ff5_l3.png?resize=13%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="13"/> is unknown at the decision time, and is only revealed after the decision is made (in <em>bandits</em> an even weaker signal is revealed, namely only the paid cost <img alt="c_t(x_t)" class="ql-img-inline-formula " height="18" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2386c8e739c9c7a4b54b88f35014ed9f_l3.png?resize=42%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="42"/>). The type of applications one has in mind is say online recommendations, where a user’s preference is only revealed once some item has been recommended to her. On the other hand in online algorithms the cost <img alt="c_t" class="ql-img-inline-formula " height="11" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9845b6b2f038ab88eb360832403e4ff5_l3.png?resize=13%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="13"/> is known at decision time. In this context the cost corresponds to a <em>request</em>, and the player has to find a way to satisfy this request (in the language of MTS the cost represents a <em>task</em>, and one gets the option to update its state so as to complete this task more efficiently, i.e., at a lower cost). Now let us discuss the performance metric. In online learning one assumes that there <em>is</em> some “hidden” good action (it is hidden in the noise, i.e., a single cost function does not say much about which actions are good, but if one takes the whole sequence into account then there is some good action that hopefully emerges). Thus it is natural to consider the following <em>regret</em> notion:</p>
<p class="ql-center-displayed-equation" style="line-height: 53px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \sum_{t=1}^T c_t(x_t) - \min_{x \in X} \sum_{t=1}^T c_t(x) \]" class="ql-img-displayed-equation " height="53" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8423d9ed97eb2b1857865f81f65b2716_l3.png?resize=191%2C53&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="191"/></p>
<p>This regret notion does not make sense for online algorithms where one may have to keep changing states to satisfy the request sequence. There one must compare to the best offline strategy, in which case additive guarantees are not attainable and one resorts to a multiplicative guarantee, the so-called competitive ratio:</p>
<p class="ql-center-displayed-equation" style="line-height: 53px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \sum_{t=1}^T \left( c_t(x_t) + d(x_t,x_{t-1}) \right) / \min_{x^* \in X^T} \sum_{t=1}^T \left( c_t(x_t^*) + d(x_t^*,x_{t-1}^*) \right) ~. \]" class="ql-img-displayed-equation " height="53" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-edd845a97f35f23d5d5a1ec6e9311ee2_l3.png?resize=457%2C53&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="457"/></p>
<p>(Note that in MTS one always assumes nonnegative cost functions so that the multicative guarantee makes sense.) The <img alt="k" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9dc53f8ecc1bcf15020c6df4c12f1c27_l3.png?resize=9%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>-server problem, introduced in Manasse, McGeoch and Sleator 90, corresponds to a metrical task system on the product state space <img alt="X^k" class="ql-img-inline-formula " height="15" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f4f07befd8b18bfbbe04d8aa59ec8107_l3.png?resize=23%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="23"/> equipped with the <a class="liinternal" href="https://en.wikipedia.org/wiki/Earth_mover%27s_distance" rel="nofollow">Earthmover distance</a> inherited by <img alt="(X,d)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-915a38cf3b448b9650171dda00b44280_l3.png?resize=44%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="44"/>, and with cost functions</p>
<p class="ql-center-displayed-equation" style="line-height: 22px;"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img alt="\[ \mathcal{C} = \{X^k \ni x \mapsto + \infty \times 1\{ r \not\in \{x(1),\hdots,x(k)\} \}; \ r \in X \} ~. \]" class="ql-img-displayed-equation " height="22" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-47f1adb64975bb52101fe12f1dc12226_l3.png?resize=439%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="439"/></p>
<p><strong>Known results</strong></p>
<p>The online learning setting is by now fairly well-understood. We know that the optimal regret for a finite action set <img alt="|X| = n" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9cc031e2a4063ef979f76fdeeb0a7b56_l3.png?resize=59%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="59"/> and bounded cost functions is <img alt="O(\sqrt{T \log(n)})" class="ql-img-inline-formula " height="22" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c269c839641da56c1651969a2ad31bb8_l3.png?resize=108%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="108"/> (see e.g., <a class="liinternal" href="https://dl.acm.org/citation.cfm?doid=258128.258179">Cesa-Bianchi, Freund, Haussler, Helmbold, Schapire and Warmuth 97</a>). In fact we even know the optimal constant (for large <img alt="n" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> and <img alt="T" class="ql-img-inline-formula " height="12" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-58f18d11e5ffdd11dd9095c427922c8b_l3.png?resize=13%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="13"/>), and we have both algorithmic and information theoretic proofs of this result. Moreover we know how to leverage combinatorial information, e.g., when <img alt="X \subset \{0,1\}^d" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0303d49c5e13db4b67916dbb938a3b36_l3.png?resize=91%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="91"/> and <img alt="\mathcal{C}" class="ql-img-inline-formula " height="12" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-28cf3bfa5ba16a20a138e948e9deb9aa_l3.png?resize=10%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="10"/> is a set of linear functions. A unifying principle that was put forth in the last decade or so is the mirror descent strategy.</p>
<p>On the other hand the situation for MTS is much worse. The optimal guarantees for finite sets are not known: the worst case (over all metric spaces of size <img alt="n" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/>) competitive ratio is known to be <img alt="\Omega(\log(n))" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78b095623b5ea4feca400e2e27c9f21f_l3.png?resize=74%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="74"/> (trivial coupon-collector style lower bound on the uniform metric) and <img alt="O(\log^2(n) \log\log(n))" class="ql-img-inline-formula " height="20" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4e2771b0f9b0d90e90b94d355167552e_l3.png?resize=159%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="159"/> (the latter bound is due to <a class="liinternal" href="https://arxiv.org/abs/cs/0406034">Fiat and Mendel 03</a>). No information theoretic analysis is known, even for the uniform metric. With combinatorial structure the situation becomes even more disastrous. That’s where the <img alt="k" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9dc53f8ecc1bcf15020c6df4c12f1c27_l3.png?resize=9%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>-server problem comes in, as a combinatorial MTS striking the best balance between simplicity and importance. For <img alt="k" class="ql-img-inline-formula " height="13" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9dc53f8ecc1bcf15020c6df4c12f1c27_l3.png?resize=9%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="9"/>-server it is conjectured that one could get a competitive ratio of <img alt="O(\log(k))" class="ql-img-inline-formula " height="18" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-aa3282f165dce006d9f76f4336115856_l3.png?resize=73%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="73"/> (the coupon-collector lower bound on uniform metric gives here <img alt="\Omega(\log(k))" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-984f7638f94ac8cd15e45608e0315753_l3.png?resize=72%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="72"/>), while the best result prior to our work was <img alt="O(\log^3(n) \log^2(k))" class="ql-img-inline-formula " height="20" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cb999309dc651f4dbff6645f16427bf6_l3.png?resize=139%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="139"/> (due to <a class="liinternal" href="https://arxiv.org/abs/1110.1580v1">Bansal, Buchbinder, Naor and Madry 11</a>), and <img alt="O(k)" class="ql-img-inline-formula " height="18" src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5978f80adc42c94bcdc874ab09e5d955_l3.png?resize=37%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" width="37"/> if one insists for a bound independent of <img alt="n" class="ql-img-inline-formula " height="8" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" width="11"/> (due to <a class="liexternal" href="http://citeseerx.ist.psu.edu/showciting?cid=149659">Koutsoupias and Papadimitriou 95</a>).</p></div></content><updated planet:format="December 17, 2017 12:28 AM">2017-12-17T00:28:07Z</updated><published planet:format="December 17, 2017 12:28 AM">2017-12-17T00:28:07Z</published><category term="Theoretical Computer Science"/><author><name>Sebastien Bubeck</name></author><source><id>https://blogs.princeton.edu/imabandit</id><link href="https://blogs.princeton.edu/imabandit/feed/" rel="self" type="application/atom+xml"/><link href="https://blogs.princeton.edu/imabandit" rel="alternate" type="text/html"/><subtitle>Random topics in optimization, probability, and statistics. By Sébastien Bubeck</subtitle><title>I’m a bandit</title><updated planet:format="December 16, 2018 04:44 PM">2018-12-16T16:44:02Z</updated><planet:http_status>200</planet:http_status><planet:module>toc</planet:module><planet:format>atom10</planet:format><planet:items_per_page>40</planet:items_per_page><planet:name>S&amp;eacute;bastian Bubeck</planet:name><planet:http_last_modified>Fri, 23 Nov 2018 17:03:44 GMT</planet:http_last_modified><planet:bozo>false</planet:bozo><planet:http_etag>&quot;7a21033bc747c1eccfdc0e4c416aa3e2&quot;</planet:http_etag><planet:css-id>s-eacute-bastian-bubeck</planet:css-id></source></entry>
