<?xml version="1.0" encoding="utf-8"?><entry xml:lang="en" xmlns="http://www.w3.org/2005/Atom" xmlns:planet="http://planet.intertwingly.net/"><id>http://mittheory.wordpress.com/?p=655</id><link href="https://mittheory.wordpress.com/2015/02/06/sketching-and-embedding-are-equivalent-for-norms/" rel="alternate" type="text/html"/><title>Sketching and Embedding are Equivalent for Norms</title><summary>Summary In this post I will show that any normed space that allows good sketches is necessarily embeddable into an space with close to . This provides a partial converse to a result of Piotr Indyk, who showed how to sketch metrics that embed into for . A cool bonus of this result is that […]<div class="commentbar"><p/></div></summary><content type="xhtml"><div xmlns="http://www.w3.org/1999/xhtml"><h2>Summary</h2>
<p>In this post I will show that any normed space that allows good sketches is necessarily embeddable into an <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> space with <img alt="p" class="latex" src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="p"/> close to <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="1"/>. This provides a partial converse to a <a href="http://www.cs.dartmouth.edu/~ac/Teach/CS49-Fall11/Papers/indyk-stable.pdf">result</a> of <a href="http://people.csail.mit.edu/indyk/">Piotr Indyk</a>, who showed how to sketch metrics that embed into <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> for <img alt="0 &lt; p \le 2" class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+p+%5Cle+2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="0 &lt; p \le 2"/>. A cool bonus of this result is that it gives a new technique for obtaining sketching lower bounds.</p>
<p>This result appeared in a <a href="http://arxiv.org/abs/1411.2577">recent paper</a> of mine that is a joint work with <a href="http://www.mit.edu/~andoni/">Alexandr Andoni</a> and <a href="http://www.wisdom.weizmann.ac.il/~robi/">Robert Krauthgamer</a>. I am pleased to report that it has been accepted to <a href="http://people.csail.mit.edu/ronitt/2015cfp.html">STOC 2015</a>.</p>
<h2>Sketching</h2>
<p>One of the exciting relatively recent paradigms in algorithms is that of <em>sketching</em>. The high-level idea is as follows: if we are interested in working with a massive object <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="x"/>, let us start with compressing it to a short sketch <img alt="\mathrm{sketch}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsketch%7D%28x%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\mathrm{sketch}(x)"/> that preserves properties of <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="x"/> we care about. One great example of sketching is the <a href="http://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma">Johnson-Lindenstrauss lemma</a>: if we work with <img alt="n" class="latex" src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="n"/> high-dimensional vectors and are interested in Euclidean distances between them, we can project the vectors on a random <img alt="O(\varepsilon^{-2} \cdot \log n)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28%5Cvarepsilon%5E%7B-2%7D+%5Ccdot+%5Clog+n%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="O(\varepsilon^{-2} \cdot \log n)"/>-dimensional subspace, and this will preserve with high probability all the pairwise distances up to a factor of <img alt="1 + \varepsilon" class="latex" src="https://s0.wp.com/latex.php?latex=1+%2B+%5Cvarepsilon&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="1 + \varepsilon"/>.</p>
<p>It would be great to understand, for which computational problems sketching is possible, and how efficient it can be made. There are quite a few nice results (both upper and lower bounds) along these lines (see, e.g., <a href="http://people.cs.umass.edu/~mcgregor/papers/12-dynamic.pdf">graph sketching</a> or a recent <a href="http://researcher.watson.ibm.com/researcher/files/us-dpwoodru/wNow.pdf">book</a> about sketching for numerical linear algebra), but the general understanding has yet to emerge.</p>
<h2>Sketching for metrics</h2>
<p>One of the main motivations to study sketching is fast computation and indexing of <em>similarity measures</em> <img alt="\mathrm{sim}(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsim%7D%28x%2C+y%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\mathrm{sim}(x, y)"/> between two objects <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="y"/>. Often times similarity between objects is modeled by some <a href="http://en.wikipedia.org/wiki/Metric_space">metric</a> <img alt="d(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=d%28x%2C+y%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d(x, y)"/> (but not always! think <a href="http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL divergence</a>): for instance the above example of the Euclidean distance falls into this category. Thus, instantiating the above general question one can ask: for which metric spaces there exist good sketches? That is, when is it possible to compute a short sketch <img alt="\mathrm{sketch}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsketch%7D%28x%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\mathrm{sketch}(x)"/> of a point <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="x"/> such that, given two sketches <img alt="\mathrm{sketch}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsketch%7D%28x%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\mathrm{sketch}(x)"/> and <img alt="\mathrm{sketch}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsketch%7D%28y%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\mathrm{sketch}(y)"/>, one is able to estimate the distance <img alt="d(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=d%28x%2C+y%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d(x, y)"/>?</p>
<p>The following communication game captures the question of sketching metrics. Alice and Bob each have a point from a metric space <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> (say, <img alt="x" class="latex" src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="x"/> and <img alt="y" class="latex" src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="y"/>, respectively). Suppose, in addition, that either <img alt="d_X(x, y) \le r" class="latex" src="https://s0.wp.com/latex.php?latex=d_X%28x%2C+y%29+%5Cle+r&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d_X(x, y) \le r"/> or <img alt="d_X(x, y) &gt; D \cdot r" class="latex" src="https://s0.wp.com/latex.php?latex=d_X%28x%2C+y%29+%3E+D+%5Ccdot+r&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d_X(x, y) &gt; D \cdot r"/> (where <img alt="r" class="latex" src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="r"/> and <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D"/> are the parameters known from the beginning). Both Alice and Bob send messages <img alt="\mathrm{sketch}(x)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsketch%7D%28x%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\mathrm{sketch}(x)"/> and <img alt="\mathrm{sketch}(y)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsketch%7D%28y%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\mathrm{sketch}(y)"/> that are <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="s"/> bits long to Charlie, who is supposed to distinguish two cases (whether <img alt="d_X(x, y)" class="latex" src="https://s0.wp.com/latex.php?latex=d_X%28x%2C+y%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d_X(x, y)"/> is small or large) with probability at least <img alt="0.99" class="latex" src="https://s0.wp.com/latex.php?latex=0.99&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="0.99"/>. We assume that all three parties are allowed to use shared randomness. Our main goal is to understand the trade-off between <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D"/> (approximation) and <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="s"/> (sketch size).</p>
<p>Arguably, the most important metric spaces are <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> spaces. Formally, for <img alt="1 \leq p \leq \infty" class="latex" src="https://s0.wp.com/latex.php?latex=1+%5Cleq+p+%5Cleq+%5Cinfty&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="1 \leq p \leq \infty"/> we define <img alt="\ell_p^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p%5Ed&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p^d"/> to be a <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d"/>-dimensional space equipped with distance</p>
<p><img alt="\|x - y\|_p = \Bigl(\sum_{i=1}^d |x_i - y_i|^p\Bigr)^{1/p}" class="latex" src="https://s0.wp.com/latex.php?latex=%5C%7Cx+-+y%5C%7C_p+%3D+%5CBigl%28%5Csum_%7Bi%3D1%7D%5Ed+%7Cx_i+-+y_i%7C%5Ep%5CBigr%29%5E%7B1%2Fp%7D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\|x - y\|_p = \Bigl(\sum_{i=1}^d |x_i - y_i|^p\Bigr)^{1/p}"/></p>
<p>(when <img alt="p = \infty" class="latex" src="https://s0.wp.com/latex.php?latex=p+%3D+%5Cinfty&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="p = \infty"/> this expression should be understood as <img alt="\max_{1 \leq i \leq d} |x_i - y_i|" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmax_%7B1+%5Cleq+i+%5Cleq+d%7D+%7Cx_i+-+y_i%7C&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\max_{1 \leq i \leq d} |x_i - y_i|"/>). One can similarly define <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> spaces for <img alt="0 &lt; p &lt; 1" class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+p+%3C+1&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="0 &lt; p &lt; 1"/>; even if the triangle inequality does not hold for this case, it is nevertheless a meaningful notion of distance.</p>
<p>It turns out that <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> spaces exhibit very interesting behavior, when it comes to sketching. Indyk <a href="http://www.cs.dartmouth.edu/~ac/Teach/CS49-Fall11/Papers/indyk-stable.pdf">showed</a> that for <img alt="0 &lt; p \le 2" class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+p+%5Cle+2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="0 &lt; p \le 2"/> one can achieve approximation <img alt="D = 1 + \varepsilon" class="latex" src="https://s0.wp.com/latex.php?latex=D+%3D+1+%2B+%5Cvarepsilon&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D = 1 + \varepsilon"/> and sketch size <img alt="s = O(1 / \varepsilon^2)" class="latex" src="https://s0.wp.com/latex.php?latex=s+%3D+O%281+%2F+%5Cvarepsilon%5E2%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="s = O(1 / \varepsilon^2)"/> for every <img alt="\varepsilon &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon+%3E+0&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\varepsilon &gt; 0"/> (for <img alt="1 \le p \le 2" class="latex" src="https://s0.wp.com/latex.php?latex=1+%5Cle+p+%5Cle+2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="1 \le p \le 2"/> this was <a href="http://www.cs.ucla.edu/~rafail/PUBLIC/36.pdf">established</a> before by Kushilevitz, Ostrovsky and Rabani). It is quite remarkable that these bounds do not depend on the dimension of a space. On the other hand, for <img alt="\ell_p^d" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p%5Ed&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p^d"/> with <img alt="p &gt; 2" class="latex" src="https://s0.wp.com/latex.php?latex=p+%3E+2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="p &gt; 2"/> the dependence on the dimension is necessary. It <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.7876">turns out</a> that for constant approximation <img alt="D = O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=D+%3D+O%281%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D = O(1)"/> the optimal sketch size is <img alt="\widetilde{\Theta}(d^{1 - 2/p})" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7B%5CTheta%7D%28d%5E%7B1+-+2%2Fp%7D%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\widetilde{\Theta}(d^{1 - 2/p})"/>.</p>
<p>Are there any other examples of metrics that admit efficient sketches (say, with constant <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D"/> and <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="s"/>)? One simple observation is that if a metric <em>embeds well</em> into <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> for <img alt="0 &lt; p \le 2" class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+p+%5Cle+2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="0 &lt; p \le 2"/>, then one can sketch this metric well. Formally, we say that a map between metric spaces <img alt="f \colon X \to Y" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Ccolon+X+%5Cto+Y&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="f \colon X \to Y"/> is an <em>embedding with distortion</em> <img alt="\widetilde{D}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BD%7D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\widetilde{D}"/>, if</p>
<p><img alt="d_X(x_1, x_2) \leq C \cdot d_Y\bigl(f(x_1), f(x_2)\bigr) \leq \widetilde{D}  \cdot d_X(x_1, x_2)" class="latex" src="https://s0.wp.com/latex.php?latex=d_X%28x_1%2C+x_2%29+%5Cleq+C+%5Ccdot+d_Y%5Cbigl%28f%28x_1%29%2C+f%28x_2%29%5Cbigr%29+%5Cleq+%5Cwidetilde%7BD%7D++%5Ccdot+d_X%28x_1%2C+x_2%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d_X(x_1, x_2) \leq C \cdot d_Y\bigl(f(x_1), f(x_2)\bigr) \leq \widetilde{D}  \cdot d_X(x_1, x_2)"/></p>
<p>for every <img alt="x_1, x_2 \in X" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2C+x_2+%5Cin+X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="x_1, x_2 \in X"/> and for some <img alt="C &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=C+%3E+0&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="C &gt; 0"/>. It is immediate to see that if a metric space <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> embeds into <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> for <img alt="0 &lt; p \le 2" class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+p+%5Cle+2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="0 &lt; p \le 2"/> with distortion <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="O(1)"/>, then one can sketch <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> with <img alt="s = O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=s+%3D+O%281%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="s = O(1)"/> and <img alt="D = O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=D+%3D+O%281%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D = O(1)"/>. Thus, we know that any metric that embeds well into <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> with <img alt="0 &lt; p \le 2" class="latex" src="https://s0.wp.com/latex.php?latex=0+%3C+p+%5Cle+2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="0 &lt; p \le 2"/> is efficiently sketchable. Are there any other examples? The amazing answer is that <em>we don’t know</em>!</p>
<h2>Our results</h2>
<p>Our result shows that for a very important class of metrics—<a href="http://en.wikipedia.org/wiki/Normed_vector_space">normed spaces</a>—embedding into <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> is the only possible way to obtain good sketches. Formally, if a normed space <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> allows sketches of size <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="s"/> for approximation <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D"/>, then for every <img alt="\varepsilon &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon+%3E+0&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\varepsilon &gt; 0"/> the space <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> embeds into <img alt="\ell_{1 - \varepsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7B1+-+%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_{1 - \varepsilon}"/> with distortion <img alt="O(sD / \varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28sD+%2F+%5Cvarepsilon%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="O(sD / \varepsilon)"/>. This result together with the above upper bound by Indyk provides a complete characterization of normed spaces that admit good sketches.</p>
<p>Taking the above result in the contrapositive, we see that non-embeddability implies lower bounds for sketches. This is great, since it potentially allows us to employ many sophisticated non-embeddability results proved by geometers and functional analysts. Specifically, we prove two new lower bounds for sketches: for the planar <a href="http://en.wikipedia.org/wiki/Earth_mover%27s_distance">Earth Mover’s Distance</a> (building on a <a href="https://web.math.princeton.edu/~naor/homepage%20files/planar-earthmover.pdf">non-embeddability theorem</a> by Naor and Schechtman) and for the <a href="http://en.wikipedia.org/wiki/Schatten_norm">trace norm</a> (non-embeddability was <a href="https://eudml.org/doc/89374">proved</a> by Pisier). In addition to it, we are able to unify certain known results: for instance, classify <img alt="\ell_p" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_p"/> spaces and the <a href="http://researcher.ibm.com/files/us-dpwoodru/jw09.pdf">cascaded norms</a> in terms of “sketchability”.</p>
<h2>Overview of the proof</h2>
<p>Let me outline the main steps of the proof of the implication “good sketches imply good embeddings”. The following definition is central to the proof. Let us call a map <img alt="f \colon X \to Y" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Ccolon+X+%5Cto+Y&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="f \colon X \to Y"/> between two metric spaces <em><img alt="(s_1, s_2, \tau_1, \tau_2)" class="latex" src="https://s0.wp.com/latex.php?latex=%28s_1%2C+s_2%2C+%5Ctau_1%2C+%5Ctau_2%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="(s_1, s_2, \tau_1, \tau_2)"/>-threshold</em>, if for every <img alt="x_1, x_2 \in X" class="latex" src="https://s0.wp.com/latex.php?latex=x_1%2C+x_2+%5Cin+X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="x_1, x_2 \in X"/>:</p>
<ul>
<li><img alt="d_X(x_1, x_2) \leq s_1" class="latex" src="https://s0.wp.com/latex.php?latex=d_X%28x_1%2C+x_2%29+%5Cleq+s_1&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d_X(x_1, x_2) \leq s_1"/> implies <img alt="d_Y\bigl(f(x_1), f(x_2)\bigr) \leq \tau_1" class="latex" src="https://s0.wp.com/latex.php?latex=d_Y%5Cbigl%28f%28x_1%29%2C+f%28x_2%29%5Cbigr%29+%5Cleq+%5Ctau_1&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d_Y\bigl(f(x_1), f(x_2)\bigr) \leq \tau_1"/>,</li>
<li><img alt="d_X(x_1, x_2) \geq s_2" class="latex" src="https://s0.wp.com/latex.php?latex=d_X%28x_1%2C+x_2%29+%5Cgeq+s_2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d_X(x_1, x_2) \geq s_2"/> implies <img alt="d_Y\bigl(f(x_1), f(x_2)\bigr) \geq \tau_2" class="latex" src="https://s0.wp.com/latex.php?latex=d_Y%5Cbigl%28f%28x_1%29%2C+f%28x_2%29%5Cbigr%29+%5Cgeq+%5Ctau_2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d_Y\bigl(f(x_1), f(x_2)\bigr) \geq \tau_2"/>.</li>
</ul>
<p>One should think of threshold maps as very weak embeddings that merely<br/>
preserve certain distance scales.</p>
<p>The proof can be divided into two parts. First, we prove that for a normed space <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> that allows sketches of size <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="s"/> and approximation <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D"/> there exists a <img alt="(1, O(sD), 1, 10)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2C+O%28sD%29%2C+1%2C+10%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="(1, O(sD), 1, 10)"/>-threshold map to a <a href="http://en.wikipedia.org/wiki/Hilbert_space">Hilbert space</a>. Then, we prove that the existence of such a map implies the existence of an embedding into <img alt="\ell_{1 - \varepsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7B1+-+%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_{1 - \varepsilon}"/> with distortion <img alt="O(sD / \varepsilon)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28sD+%2F+%5Cvarepsilon%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="O(sD / \varepsilon)"/>.</p>
<p>The first half goes roughly as follows. Assume that there is no <img alt="(1, O(sD), 1, 10)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2C+O%28sD%29%2C+1%2C+10%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="(1, O(sD), 1, 10)"/>-threshold map from <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> to a Hilbert space. Then, by convex duality, this implies certain Poincaré-type inequalities on <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/>. This, in turn, implies sketching lower bounds for <img alt="\ell_{\infty}^k(X)" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7B%5Cinfty%7D%5Ek%28X%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_{\infty}^k(X)"/> (the direct sum of <img alt="k" class="latex" src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="k"/> copies of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/>, where the norm is definied as the maximum of norms of the components) by a <a href="http://people.csail.mit.edu/mip/papers/ccedit/paper.pdf">result</a> of Andoni, Jayram and Pătrașcu (which is based on a very important notion of <a href="http://www.cs.princeton.edu/~mbraverm/pmwiki/index.php?n=Research.STOC13Workshop">information complexity</a>). Then, crucially using the fact that <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> is a normed space, we conclude that <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> itself does not have good sketches (this step follows from the fact that every normed space is of <a href="http://ncatlab.org/nlab/show/type+%28functional+analysis%29">type</a> <img alt="1" class="latex" src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="1"/> and is of cotype <img alt="\infty" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cinfty&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\infty"/>).</p>
<p>The second half uses tools from nonlinear functional analysis. First, building on an <a href="http://arxiv.org/pdf/math/0410427.pdf">argument</a> of Johnson and Randrianarivony, we show that for normed spaces <img alt="(1, O(sD), 1, 10)" class="latex" src="https://s0.wp.com/latex.php?latex=%281%2C+O%28sD%29%2C+1%2C+10%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="(1, O(sD), 1, 10)"/>-threshold map into a Hilbert space implies a <em>uniform embedding</em> into a Hilbert space—that is, a map <img alt="f \colon X \to H" class="latex" src="https://s0.wp.com/latex.php?latex=f+%5Ccolon+X+%5Cto+H&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="f \colon X \to H"/>, where <img alt="H" class="latex" src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="H"/> is a Hilbert space such that</p>
<p><img alt="L\bigl(\|x_1 - x_2\|_X\bigr) \leq      \bigl\|f(x_1) - f(x_1)\bigr\|_H \leq U\bigl(\|x_1 - x_2\|_X\bigr),  " class="latex" src="https://s0.wp.com/latex.php?latex=L%5Cbigl%28%5C%7Cx_1+-+x_2%5C%7C_X%5Cbigr%29+%5Cleq++++++%5Cbigl%5C%7Cf%28x_1%29+-+f%28x_1%29%5Cbigr%5C%7C_H+%5Cleq+U%5Cbigl%28%5C%7Cx_1+-+x_2%5C%7C_X%5Cbigr%29%2C++&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="L\bigl(\|x_1 - x_2\|_X\bigr) \leq      \bigl\|f(x_1) - f(x_1)\bigr\|_H \leq U\bigl(\|x_1 - x_2\|_X\bigr),  "/></p>
<p>where <img alt="L, U \colon [0; \infty) \to [0; \infty)" class="latex" src="https://s0.wp.com/latex.php?latex=L%2C+U+%5Ccolon+%5B0%3B+%5Cinfty%29+%5Cto+%5B0%3B+%5Cinfty%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="L, U \colon [0; \infty) \to [0; \infty)"/> are non-decreasing functions such that <img alt="L(t) &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=L%28t%29+%3E+0&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="L(t) &gt; 0"/> for every <img alt="t &gt; 0" class="latex" src="https://s0.wp.com/latex.php?latex=t+%3E+0&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="t &gt; 0"/> and <img alt="U(t) \to 0" class="latex" src="https://s0.wp.com/latex.php?latex=U%28t%29+%5Cto+0&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="U(t) \to 0"/> as <img alt="t \to 0" class="latex" src="https://s0.wp.com/latex.php?latex=t+%5Cto+0&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="t \to 0"/>. Both <img alt="L" class="latex" src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="L"/> and <img alt="U" class="latex" src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="U"/> are allowed to depend <em>only on <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="s"/> and <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D"/></em>. This step uses a certain Lipschitz extension-type theorem and averaging via bounded invariant means. Finally, we conclude the proof by applying theorems of <a href="http://link.springer.com/article/10.1007%2FBF02786521">Aharoni-Maurey-Mityagin</a> and <a href="http://www.mathnet.ru/php/archive.phtml?wshow=paper&amp;jrnid=rm&amp;paperid=5429&amp;option_lang=eng">Nikishin</a> and obtain a desired (linear) embedding of <img alt="X" class="latex" src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="X"/> into <img alt="\ell_{1 - \varepsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7B1+-+%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_{1 - \varepsilon}"/>.</p>
<h2>Open problems</h2>
<p>Let me finally state several open problems.</p>
<p>The first obvious open problem is to extend our result to as large class of general metric spaces as possible. Two notable examples one should keep in mind are the <a href="http://arxiv.org/abs/1305.4581">Khot-Vishnoi space</a> and the <a href="https://web.math.princeton.edu/~naor/homepage%20files/qq.pdf">Heisenberg group</a>. In both cases, a space admits good sketches (since both spaces are embeddable into <img alt="\ell_2" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_2&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_2"/>-squared), but neither of them is embeddable into <img alt="\ell_1" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_1&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_1"/>. I do not know, if these spaces are embeddable into <img alt="\ell_{1 - \varepsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7B1+-+%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_{1 - \varepsilon}"/>, but I am inclined to suspect so.</p>
<p>The second open problem deals with <em>linear</em> sketches. For a normed space, one can require that a sketch is of the form <img alt="\mathrm{sketch}(x) = Ax" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsketch%7D%28x%29+%3D+Ax&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\mathrm{sketch}(x) = Ax"/>, where <img alt="A" class="latex" src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="A"/> is a random matrix generated using shared randomness. Our result then can be interpreted as follows: any normed space that allows sketches of size <img alt="s" class="latex" src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="s"/> and approximation <img alt="D" class="latex" src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="D"/> allows a linear sketch with <em>one</em> linear measurement and approximation <img alt="O(sD)" class="latex" src="https://s0.wp.com/latex.php?latex=O%28sD%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="O(sD)"/> (this follows from the fact that for <img alt="\ell_{1 - \varepsilon}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7B1+-+%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_{1 - \varepsilon}"/> there are good linear sketches). But can we always construct a linear sketch of size <img alt="f(s)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28s%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="f(s)"/> and approximation <img alt="g(D)" class="latex" src="https://s0.wp.com/latex.php?latex=g%28D%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="g(D)"/>, where <img alt="f(\cdot)" class="latex" src="https://s0.wp.com/latex.php?latex=f%28%5Ccdot%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="f(\cdot)"/> and <img alt="g(\cdot)" class="latex" src="https://s0.wp.com/latex.php?latex=g%28%5Ccdot%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="g(\cdot)"/> are some (ideally, not too quickly growing) functions?</p>
<p>Finally, the third open problem is about spaces that allow essentially no non-trivial sketches. Can one characterize <img alt="d" class="latex" src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="d"/>-dimensional normed spaces, where any sketch for approximation <img alt="O(1)" class="latex" src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="O(1)"/> must have size <img alt="\Omega(d)" class="latex" src="https://s0.wp.com/latex.php?latex=%5COmega%28d%29&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\Omega(d)"/>? The only example I can think of is a space that contains a subspace that is close to <img alt="\ell_{\infty}^{\Omega(d)}" class="latex" src="https://s0.wp.com/latex.php?latex=%5Cell_%7B%5Cinfty%7D%5E%7B%5COmega%28d%29%7D&amp;bg=ffffff&amp;fg=404040&amp;s=0" title="\ell_{\infty}^{\Omega(d)}"/>. Is this the only case?</p>
<p>—<a href="http://ilyaraz.org">Ilya</a></p></div></content><updated planet:format="February 06, 2015 05:54 AM">2015-02-06T05:54:53Z</updated><published planet:format="February 06, 2015 05:54 AM">2015-02-06T05:54:53Z</published><category term="algorithms"/><category term="complexity"/><category term="data structures"/><category term="geometry"/><category term="STOC"/><author><name>mittheory</name></author><source><id>https://mittheory.wordpress.com</id><logo>https://s0.wp.com/i/buttonw-com.png</logo><link href="https://mittheory.wordpress.com/feed/" rel="self" type="application/atom+xml"/><link href="https://mittheory.wordpress.com" rel="alternate" type="text/html"/><link href="https://mittheory.wordpress.com/osd.xml" rel="search" type="application/opensearchdescription+xml"/><link href="https://mittheory.wordpress.com/?pushpress=hub" rel="hub" type="text/html"/><subtitle>A student blog of MIT CSAIL Theory of Computation Group</subtitle><title>Not so Great Ideas in Theoretical Computer Science</title><updated planet:format="December 17, 2018 05:30 AM">2018-12-17T05:30:10Z</updated><planet:module>toc</planet:module><planet:format>atom10</planet:format><planet:http_last_modified>Thu, 12 Apr 2018 01:31:44 GMT</planet:http_last_modified><planet:bozo>false</planet:bozo><planet:items_per_page>40</planet:items_per_page><planet:css-id>mit-csail-student-blog</planet:css-id><planet:face>csail.png</planet:face><planet:name>MIT CSAIL student blog</planet:name><planet:http_location>https://mittheory.wordpress.com/feed/</planet:http_location><planet:http_status>301</planet:http_status></source></entry>
